{
  "hash": "04bce42248524f633da64f72a02b99d8",
  "result": {
    "markdown": "---\ntitle: \"Sentiment towards The Rings of Power\"\nsubtitle: \"Comparing the responses of book readers and non-book readers\"\nauthor: \"James Otto\"\ndate: \"10/15/2022\"\nimage: rings-of-power.png\nformat: \n  html:\n    code-fold: true\n    toc: true\nexecute:\n  echo: true\n  cache: true\nresources: \n  - \"data/*.csv\"\n---\n\n\nThe Rings of Power is a controversial show that fills in \nthe time before the events in J. R. R. Tolkien's The Lord of the Rings with what some\nsay is creative reimagining and others decry as glorified fan fiction.\nThe root cause of this debate is that the show's creators do not have the rights to all of the  relevant source material. \nAs a result they have had to go against what is technically canon,\nplaying loose with timelines and at times making up major plot points.\n\nIts main subreddit, [/r/RingsofPower](https://reddit.com/r/RingsofPower),\nhas two weekly discussion threads per episode---one for book readers and one for non-book readers.\nNow that the first season has wrapped up, these threads represent a cool statistical opportunity: \nwe can try to compare the feelings and reactions of these two groups across each episode!\n\nNow, a **warning**: this post analyzes and visualizes text data from [reddit.com](https://reddit.com).\nThis includes text with coarse language that some may find offensive---if that is you, maybe skip this post.\n\n![](gifs/fly-you-fools.gif){fig-align=\"center\"}\n\nNow, with that out of the way, let's load all of the packages we'll be needing:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# Interacting with Reddit API:\nlibrary(\"httr\")\nlibrary(\"jsonlite\")\n\n# Manipulating data:\nlibrary(\"tidyverse\")\nlibrary(\"tidytext\")\nlibrary(\"glue\")\n\n# Plotting:\nlibrary(\"ggwordcloud\")\nlibrary(\"showtext\")\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n## A brief introduction to the Reddit API\n\nUsing tools from [**httr**](https://github.com/r-lib/httr) and [**jsonlite**](https://github.com/jeroen/jsonlite) we can easily query the Reddit API (documented [here](https://www.reddit.com/dev/api/)) .\nHere, we get the 50 highest voted top-level comments from [this thread](https://www.reddit.com/r/RingsofPower/comments/xxoyqz) on Episode 7.\n\n::: {.cell hash='Rings-of-Power_cache/html/unnamed-chunk-3_9bf90d5e5ad15f5ded09f61989b6ff24'}\n\n```{.r .cell-code  code-fold=\"false\"}\nres <- \n  GET(\n    \"https://www.reddit.com/r/RingsofPower/comments/xxoyqz.json?sort=top&depth=1&limit=50\",\n    add_headers(\"user-agent\" = \"Rings-of-Power-Scraping\")\n  )\n\ndata <- fromJSON(rawToChar(res$content))\ndata <- data$data$children[[2]]$data\n```\n:::\n\n\nAfter some manipulation, `data` is now a `data.frame` with one row per comment and lots of columns, most of which are irrelevant to this analysis.\nThe columns we care about are `data$score` (each comment's votes) and `data$body` (the textual content of each comment):\n\n\n::: {.cell hash='Rings-of-Power_cache/html/unnamed-chunk-4_bbb94f12b157f878f381bb1f91fbc198'}\n\n```{.r .cell-code  code-fold=\"false\"}\ndata$score\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 165 142  93  91  87  84  81  70  64  66  60  55  54  52  52  42  49  44  41\n[20]  39  40  36  38  37  36  42  32  39  35  32  30  31  32  32  29  28  30  29\n[39]  28  26  27  30  28  25  27  24  23  21  23  19  NA\n```\n:::\n\n```{.r .cell-code  code-fold=\"false\"}\ndata$body[1:3]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"That speech about Harfoots staying true to each other was hilarious after they left him and his family for dead over a sprained ankle.\"                                            \n[2] \"What is with the PowerPoint Mordor text?!\\nYOU HAVE A GOOD ACTOR RIGHT THERE TO SAY MORDOR?\\nThen all the orc boys and gals coulda been like MORDOR MORDOR MORDOR\"                 \n[3] \"I was holding out hope that the “mithril will save the elves” plot line was a misdirect and the result of Annatar trying to deceive Gil-Galad. \\n\\nNope. Mithril is magical. \\n\\nK\"\n```\n:::\n:::\n\n\nThis looks promising, the scores are decreasing and the text looks like reddit comments! \nCross-referencing with the previously linked thread we can see that everything is working as intended, \nnow it's time to scale this example up.\n\n## All the data\n\nThis step is considerably more complicated, we need to get the 50 highest voted top-level comments for each discussion thread and \nthen use tools from [**tidytext**](https://github.com/juliasilge/tidytext) to [\"tokenize\"](https://www.tidytextmining.com/tidytext.html#the-unnest_tokens-function) each comment and identify words with \"positive\" and \"negative\" sentiments.\n\nFor now on, I'm going to collapse the code for manipulating data and generating graphics.\nIf you are interested I encourage you to look through how I've done everything,\nbut know that this post is not a guide on how to perform sentiment analysis.\nI highly recommend [Text Mining with R: A Tidy Approach](https://www.tidytextmining.com/) by Julia Silge and David Robinson if you would like to \nlearn about how to use these tools.\n\nThe plot below shows the 20 most frequently occurring positive and negative words from the combined threads,\naccording to the [Bing lexicon](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html):\n\n\n::: {.cell hash='Rings-of-Power_cache/html/unnamed-chunk-5_b0efcacd913fb3382af01281eb5a76c3'}\n\n```{.r .cell-code}\ndf_urls <- \n  tibble(\n    episode = rep(2:8, times = 2),\n    book = rep(c(TRUE, FALSE), each = 7),\n    url = c(\n      \n      # Book Spoiler threads:\n      \"x3qfr2\", # Ep 1, 2\n      \"x9ngql\", # Ep 3\n      \"xfgxa1\", # Ep 4\n      \"xlmuu5\", # Ep 5\n      \"xrrbrm\", # Ep 6\n      \"xxoyqz\", # Ep 7\n      \"y3j1zg\", # Ep 8\n      \n      # Non-Spoiler threads:\n      \"x3qfqz\", # Ep 1, 2\n      \"x9ngqa\", # Ep 3\n      \"xfgx9y\", # Ep 4\n      \"xlmurh\", # Ep 5\n      \"xrrbtm\", # Ep 6\n      \"xxoyvo\", # Ep 7\n      \"y3j23u\"  # Ep 8\n      \n    )\n  ) |>\n  mutate(\n    url = glue(\"https://www.reddit.com/r/RingsofPower/comments/{url}.json?sort=top&depth=1&limit=50\")\n  )\n\ncomments_as_df <- function(url) {\n  \n  # Need to set user-agent header to avoid 429 error\n  res <- GET(url, add_headers(\"user-agent\" = \"Rings-of-Power-Scraping\"))\n  data <- fromJSON(rawToChar(res$content))\n  data <- data$data$children[[2]]$data \n  \n  data |>\n    select(body, score) |>\n    mutate(comment_id = 1:n())\n  \n}\n\ndf_urls <- df_urls |>\n  rowwise() |>\n  mutate(\n    comments = list(comments_as_df(url)),\n  )\n\n# For each element (data.frame) in df_urls$comments,\n# we're tokenizing with unnest_tokens() and removing stop words:\n# df_urls$comments[[1]] |>\n#   unnest_tokens(word, body) |>\n#   anti_join(stop_words)\n\ndf_urls <- df_urls |>\n  mutate(\n    tidy_body = list(unnest_tokens(comments, word, body)),\n    tidy_body = list(anti_join(tidy_body, stop_words))\n  )\n\ndf_words <- df_urls |>\n  unnest(tidy_body) |>\n  select(episode, book, comment_id, word) |>\n  inner_join(get_sentiments(\"bing\")) \n\ndf_words |>\n  count(word, sentiment, sort = TRUE) |>\n  group_by(sentiment) |>\n  slice_max(n, n = 20) |>\n  mutate(word = reorder(word, n)) |>\n  ggplot(aes(n, word, fill = sentiment)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(vars(sentiment), ncol = 1, scales = \"free_y\") +\n  labs(\n    y = NULL,\n    x = \"Instances\"\n  )\n```\n\n::: {.cell-output-display}\n![](Rings-of-Power_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='Rings-of-Power_cache/html/unnamed-chunk-6_4f886039eca417bdf05e790a4d1dcce5'}\n\n:::\n\n\nA few thoughts on the above plot.\nFirst, we see that Redditors do indeed love their four letter words---this is no surprise.\nSecond (and more important), it looks like this naive attempt at sentiment analysis is getting hung up on words with particular meanings in the context of The Rings of Power.\nFor example, 3 out of 5 of the most common \"negative\" words (`\"plot\"`, `\"stranger\"`, `\"evil\"`) are obviously not conveying a negative sentiment, each with a specific neutral meaning in fantasy in general or in relation to the happenings in the show.\nLet's remove a few of the obvious false negatives/positives and see how the resulting plot looks:\n\n\n::: {.cell hash='Rings-of-Power_cache/html/unnamed-chunk-7_19b57073f3e8a78e6350372aca0a2510'}\n\n```{.r .cell-code}\ndf_words <- df_words |>\n  filter(\n    ! word %in% c(\n      # False-Negatives:\n      \"plot\", \"stranger\", \"evil\", \"dead\", \"death\", \"doom\", \"die\",\n      \"kill\", \"died\", \"conflict\", \"tension\", \"corrupted\", \"forged\",\n      # False-Positives:\n      \"magic\", \"powerful\"\n    )\n  )\n\ndf_words |>\n  count(word, sentiment, sort = TRUE) |>\n  group_by(sentiment) |>\n  slice_max(n, n = 20) |>\n  mutate(word = reorder(word, n)) |>\n  ggplot(aes(n, word, fill = sentiment)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(vars(sentiment), ncol = 1, scales = \"free_y\") +\n  labs(\n    y = NULL,\n    x = \"Instances\"\n  )\n```\n\n::: {.cell-output-display}\n![](Rings-of-Power_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nMuch better!\nNow that we feel more confident about the words that we've identified as positive and negative,\nlet's proceed with a more in-depth analysis.\n\n## Analyzing trends\n\nAll that's left for us to do is to compare the average sentiment between the book and non-book discussions.\nTo do that, we'll assign a score of +1 to positive words and -1 to negative words and \ncompute the \"average sentiment\" for comments in each thread:\n\n\n::: {.cell hash='Rings-of-Power_cache/html/unnamed-chunk-8_d66da7f1cad444cc85d31a3c1f3b3ca6'}\n\n```{.r .cell-code}\ndf_sentiments <- df_words |>\n  count(episode, book, comment_id, sentiment) |>\n  group_by(episode, book) |>\n  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) |>\n  mutate(sentiment = positive - negative) |>\n  summarize(avg_sentiment = mean(sentiment))\n\nggplot(df_sentiments, aes(episode, avg_sentiment, color = book, group = book)) +\n  geom_abline(slope = 0, intercept = 0, linetype = \"dashed\") +\n  geom_point() +\n  geom_path() +\n  scale_color_manual(NULL, values = c(\"slateblue\", \"firebrick\"), labels = c(\"Non-Book Readers       \", \"Book Readers\")) +\n  scale_x_continuous(breaks = 2:8, labels = c(\"1 + 2\", 3:8)) +\n  theme(legend.position = \"top\")\n```\n\n::: {.cell-output-display}\n![](Rings-of-Power_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nInteresting! \nIt looks like non-book readers were initially positive about the show\nbut slowly and consistently trended to be more negative over time,\nwhereas book readers have been consistently negative.\nBoth groups seem to have experienced an increase in average sentiment with the finale,\nan effect that is more pronounced in the case of the non-book readers.\nThis generally agrees with my anecdotal experiences from talking with fellow Tolkien fans,\nhowever I expected the sentiment around the finale to be significantly more negative.\n\nAdding some formatting, we can get a more visually interesting graphic:\n\n\n::: {.cell hash='Rings-of-Power_cache/html/unnamed-chunk-9_9eea61ca67d33f75bf3f4a523656316d'}\n\n```{.r .cell-code}\nfont_add_google(\"MedievalSharp\")\nfont_add_google(\"Roboto Condensed\")\n\nshowtext_auto()\n\n# Save w/ width = 1600px and height = 900px\nggplot(df_sentiments, aes(episode, avg_sentiment, color = book, group = book)) +\n  geom_abline(slope = 0, intercept = 0) +\n  geom_point(size = 2.5, show.legend = FALSE) +\n  geom_path(size = 1.5, key_glyph = draw_key_timeseries) +\n  scale_color_manual(NULL, values = c(\"#376f52\", \"#47637e\"), labels = c(\"Non-Book Readers       \", \"Book Readers\")) +\n  scale_x_continuous(breaks = 2:8, labels = c(\"1 & 2\", 3:8)) +\n  labs(\n    x = \"Episode\",\n    y = \"Average Sentiment\",\n    caption = \"Data from /r/RingsofPower \\n Created by @jamesotto852\"\n  ) +\n  theme(\n    text = element_text(\"MedievalSharp\", colour = \"#534137\"),\n    plot.caption = element_text(\"Roboto Condensed\", size = 15),\n    axis.title = element_text(size = 21),\n    axis.text = element_text(size = 15),\n    axis.title.y = element_text(margin = margin(r = 10)),\n    legend.text = element_text(size = 18),\n    legend.position = \"top\",\n    legend.key.size = unit(.4, \"cm\"),\n    panel.grid.major.y = element_line(colour = alpha(\"black\", .1)),\n    panel.grid.major.x = element_blank(),\n    plot.background = element_rect(fill = \"#ffe791\"),\n    plot.margin = unit(rep(.8, 4), \"cm\")\n  )\n```\n:::\n\n![](Plots/Trend.png)\n\n## Final thoughts\n\nWhile the results we found are interesting it's important to remember that this is a very simple analysis \nbased on positive and negative associations of individual words.\nWhile we did our best to remove words that were obviously being misclassified, \nI am sure that that there are still words that are being incorrectly identified as positive or negative\nthat are biasing our results.\n\nA more involved analysis is certainly called for; for example it would be good to consider larger\n[\"n-grams\"](https://www.tidytextmining.com/ngrams.html#ngrams),\nallowing our tokens to consist of sequences of words.\nThis approach would be more robust and would likely \nresult in more interesting and nuanced conclusions.\n\nIf you are interested in analyzing this data on your own, \n<!-- I have made the data used in this analysis [available for download](/posts/2022-10-15-Rings-of-Power/data/TRoP_comment_data.csv){download}. -->\nI have made the data used in this analysis <a href=\"/posts/2022-10-15-Rings-of-Power/data/TRoP_comment_data.csv\" download=\"TRoP_comment_data.csv\">available for download</a>.\nIf you find anything please [let me know](https://twitter.com/jamesotto852)!\n\n### Bonus: some word clouds!\n\n[**ggwordcloud**](https://github.com/lepennec/ggwordcloud) is a really powerful package which\nprovides robust tools for making word clouds within the **ggplot2** framework.\nBelow, we include a word cloud with the 20 most popular positive and negative words,\nsized according to their relative frequency:\n\n\n::: {.cell hash='Rings-of-Power_cache/html/unnamed-chunk-10_f2f0471ff77c41524cbb7ed918f490e5'}\n\n```{.r .cell-code}\ndf_words |>\n  count(word, sentiment, sort = TRUE) |>\n  group_by(sentiment) |>\n  slice_max(n, n = 20) |>\n  ungroup() |>\n  arrange(desc(n)) |>\n  ggplot(aes(label = word, size = n, color = sentiment)) +\n  geom_text_wordcloud(family = \"MedievalSharp\") +\n  geom_text_wordcloud() +\n  scale_radius(range = c(0, 40), limits = c(0, NA)) +\n  scale_color_manual(values = c(\"#f4142e\", \"#2b5a4a\")) +\n  theme_void() +\n  theme(\n    panel.background = element_rect(fill = \"#ffe791\")\n  )\n```\n:::\n\n![](Plots/Word-Cloud.png)\n\nAnd now, in everyone's favorite secret shape:\n\n\n::: {.cell hash='Rings-of-Power_cache/html/unnamed-chunk-11_bf435938c287286361c3aa630cf8040c'}\n\n```{.r .cell-code}\nmask <- png::readPNG(here::here(\"posts/2022-10-15-Rings-of-Power/Sauron Symbol.png\"))\n\n# Save with width = 2000px, height = 1355px\ndf_words |>\n  count(word, sentiment, sort = TRUE) |>\n  group_by(sentiment) |>\n  slice_max(n, n = 35) |>\n  ungroup() |>\n  slice_sample(prop = 1) |>\n  mutate(angle = 45 * rnorm(n(), sd = .5)) |>\n  ggplot(aes(label = word, size = n, color = sentiment, angle = angle)) +\n  geom_text_wordcloud(family = \"MedievalSharp\", mask = mask, eccentricity = .35) +\n  scale_radius(range = c(2, 17), limits = c(1, NA)) +\n  scale_color_manual(values = c(\"#f4142e\", \"#2b5a4a\")) +\n  theme_void() +\n  theme(\n    panel.background = element_rect(fill = \"#ffe791\")\n  )\n```\n:::\n\n![](Plots/Word-Cloud-Sigil.png)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}